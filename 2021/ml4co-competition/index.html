<!DOCTYPE HTML>
<!--
	Stellar by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html lang="en">

<head>
	<title>Machine Learning for Combinatorial Optimization - NeurIPS 2021 Competition</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1" />
	<!--[if lte IE 8]><script src="/assets/js/ie/html5shiv.js"></script><![endif]-->
	<link rel="stylesheet" href="/assets/sass/2021_competition.css" />
	<link rel="stylesheet" href="style/main.css" />
	<!--[if lte IE 9]><link rel="stylesheet" href="/assets/css/ie9.css" /><![endif]-->
	<!--[if lte IE 8]><link rel="stylesheet" href="/assets/css/ie8.css" /><![endif]-->
	<!-- Courtesy of faviconit.com for providing all favicons-->
	<link rel="shortcut icon" href="/favicon/favicon.ico">
	<link rel="icon" sizes="16x16 32x32 64x64" href="/favicon/favicon.ico">
	<link rel="icon" type="image/png" sizes="196x196" href="/favicon/favicon-192.png">
	<link rel="icon" type="image/png" sizes="160x160" href="/favicon/favicon-160.png">
	<link rel="icon" type="image/png" sizes="96x96" href="/favicon/favicon-96.png">
	<link rel="icon" type="image/png" sizes="64x64" href="/favicon/favicon-64.png">
	<link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16.png">
	<link rel="apple-touch-icon" href="/favicon/favicon-57.png">
	<link rel="apple-touch-icon" sizes="114x114" href="/favicon/favicon-114.png">
	<link rel="apple-touch-icon" sizes="72x72" href="/favicon/favicon-72.png">
	<link rel="apple-touch-icon" sizes="144x144" href="/favicon/favicon-144.png">
	<link rel="apple-touch-icon" sizes="60x60" href="/favicon/favicon-60.png">
	<link rel="apple-touch-icon" sizes="120x120" href="/favicon/favicon-120.png">
	<link rel="apple-touch-icon" sizes="76x76" href="/favicon/favicon-76.png">
	<link rel="apple-touch-icon" sizes="152x152" href="/favicon/favicon-152.png">
	<link rel="apple-touch-icon" sizes="180x180" href="/favicon/favicon-180.png">
	<meta name="msapplication-TileColor" content="#FFFFFF">
	<meta name="msapplication-TileImage" content="/favicon/favicon-144.png">
	<meta name="msapplication-config" content="/favicon/browserconfig.xml">
	<!-- Open Graph Protocol for Social Media preview -->
	<meta property="og:title" content="Machine Learning for Combinatorial Optimization - NeurIPS 2021 Competition"/>
	<meta property="og:site_name" content="ML4CO Competition"/>
	<meta property="og:url" content="https://www.ecole.ai/2021/ml4co-competition"/>
	<meta property="og:type" content="website"/>
	<meta property="og:image" content="/images/ecole-logo.png" />
	<meta property="og:description"
		content="The Machine Learning for Combinatorial Optimization (ML4CO) competition aims at
						 improving a state-of-the-art mathematical solver by replacing several key heuristic
						 components with machine learning models."/>
</head>

<body>

<!-- Wrapper -->
<div id="wrapper">

<!-- Header -->
<header id="header" class="alt">
	<h1>Machine Learning for Combinatorial Optimization</h1>
	<p>NeurIPS 2021 Competition</p>
</header>

<!-- Nav -->
<nav id="nav">
	<ul>
		<li><a href="#challenges" class="active">Challenges</a></li>
		<li><a href="#metrics">Metrics</a></li>
		<li><a href="#datasets">Datasets</a></li>
		<li><a href="#rules">Rules</a></li>
		<li><a href="#getting-started">Getting started</a></li>
		<li><a href="#leaderboard">Leaderboard</a></li>
	</ul>
</nav>

<!-- Main -->
<div id="main">


	<section class="main">
		<div class="spotlight">
			<div class="content" style="width: 100%; text-align: center;">
				<img style="border: 0; border-radius: 0; width: 20em; margin: auto;" src="images/ml4co-final.png" alt="ML4CO Competition logo"/>
			</div>
		</div>
	</section>

	<section class="main" style="border-top: 0;">
		<div class="spotlight">
			<div class="content">
				<header class="major">
					<h2>Introduction</h2>
				</header>
			</div>
		</div>
		<div class="spotlight">
			<div class="content">
				<p>
					The Machine Learning for Combinatorial Optimization (ML4CO)
					NeurIPS 2021
					competition aims at improving state-of-the-art combinatorial
					optimization solvers by replacing key <b>heuristic components</b>
					with <b>machine learning models</b>.
					The competition's main scientific question is the following:
					<em>is machine learning a viable option for improving
					traditional combinatorial optimization solvers on
					specific problem distributions, when historical data is available ? </em>
				</p>
			</div>
			<span class="image" style="border: 0; border-radius: 0; width: 15em; text-align: center;">
				<a href="https://neurips.cc/Conferences/2021/CompetitionTrack" style="border-bottom-style: none;">
					<img style="border: 0; border-radius: 0; width: 15em; margin: auto;" src="images/neurips-logo-new.png" alt="NeurIPS logo"/>
				</a>
			</span>
		</div>
		<div class="spotlight">
			<div class="content">
				<p>
					While most combinatorial optimization solvers are presented
					as general-purpose, <em>one-size-fits-all</em> algorithms, the
					ML4CO competition focuses on the design of
					<b>application-specific algorithms</b> from historical data.
					This general problem captures a highly practical scenario
					relevant to many application areas, where a practitioner
					repeatedly solves problem instances from a specific
					distribution, with redundant patterns and characteristics. 
					For example, managing a large-scale energy
					distribution network requires solving very similar CO
					problems on a daily basis, with a fixed power grid
					structure while only the demand changes over time. This
					change of demand is hard to capture by hand-engineered
					expert rules, and ML-enhanced approaches offer a possible
					solution to detect typical patterns in the demand history.
					Other examples include crew scheduling problems that have
					to be solved daily or weekly with minor variations, or
					vehicle routing where the traffic conditions change over
					time, but the overall transportation network does not.
				</p>
			</div>
			<span class="image" style="border: 0; border-radius: 0; width: 15em; text-align: center;">
				<a href="https://www.scipopt.org/" style="border-bottom-style: none;">
					<img style="border: 0; border-radius: 0; width: 12em; margin: auto; display: inline-block;" src="images/skippy_logo_ml4co.png" alt="SCIP logo"/>
				</a>
			</span>
		</div>
		<div class="spotlight">
			<div class="content">
				<p>
					The competition features <b>three challenges for ML</b>,
					each corresponding to a specific control task arising in
					the open-source solver <a href="https://www.scipopt.org/">SCIP</a>,
					and exposed through a unified OpenAI-gym API
					based on the Python library
					<a href="https://www.ecole.ai/">Ecole</a>.
					For each challenge, participants will be evaluated on
					<b>three problem benchmarks</b> originating from diverse
					application areas, each represented as a collection
					of <b>mixed-integer linear program</b> (MILP) instances.
					Benchmark-specific submissions are encouraged (algorithms
					or trained ML models), but of course generic submissions
					that work for all three benchmarks are allowed.
				</p>
				<p>
					<em>Note: while we encourage solutions derived from the
					machine learning and reinforcement learning paradigms, any
					algorithmic solution respecting the competition's API is
					accepted.</em>
				</p>
			</div>
			<span class="image" style="border: 0; border-radius: 0; width: 15em; text-align: center;">
				<a href="https://doc.ecole.ai/" style="border-bottom-style: none;">
					<img style="border: 0; border-radius: 0; width: 13em; margin: auto; display: inline-block;" src="/images/ecole-logo.png" alt="Ecole logo"/>
				</a>
			</span>
		</div>
		<div class="content">
			<p>
			Important dates (<a href="https://en.wikipedia.org/wiki/Anywhere_on_Earth">anywhere on earth</a> time zone):
				<ul>
					<li>
						<b>Jul 1st '21</b> - competition start, release of the training datasets
					</li>
					<li>
						<b>Oct 14th '21</b> - registration deadline, no new team is accepted past this date
					</li>
					<li>
						<b>Oct 21st '21</b> - submission deadline, <em>no submission is accepted past this date</em>
					</li>
					<li>
						<b>Nov 14th '21</b> - final result annoucement and declaration of the winners
					</li>
					<li>
						<b>December '21</b> - virtual event at NeurIPS with poster session for all participants
					</li>
					<li>
						<b>February '22</b> - official report with winner contributions, to be published in PMLR
					</li>
				</ul>
			</p>
		</div>
		<div class="spotlight">
			<div class="content">
				<p>
					This event is sponsored by <a href="https://www.computecanada.ca/">Compute Canada</a>, <a href="https://www.calculquebec.ca/en/">Calcul Québec</a> and <a href="https://www.westgrid.ca/">Westgrid</a> who graciously provide the infrastructure and compute ressources to run the competition.
				</p>
			</div>
		</div>
		<div class="spotlight">
			<div class="content" style="width: 100%; text-align: center; border: 0; border-radius: 0;">
				<div style="height: 100%; display:inline-block; text-align: center; vertical-align:middle;">
					<img style="border: 0; border-radius: 0; width: 16em; margin: auto;" src="images/computecanada_logo_bi.png" alt="Compute Canada logo"/>
				</div><div style="height: 100%; display:inline-block; text-align: center; vertical-align:middle;">
					<img style="border: 0; border-radius: 0; width: 8em; margin: auto; margin-left: 2em; margin-right: 2em;" src="images/calculquebec_logo_medium.png" alt="Calcul Québec logo"/>
				</div><div style="height: 100%; display:inline-block; text-align: center; vertical-align:middle;">
					<img style="border: 0; border-radius: 0; width: 10em; margin: auto;" src="images/westgrid_logo_2016.png" alt="Westgrid logo"/>
				</div>
			</div>
		</div>
	</section>

	<!-- Challenges -->
	<section id="challenges" class="main">
		<div class="spotlight">
			<div class="content">
				<header class="major">
					<h2>Challenges</h2>
				</header>
				<p>
					We propose <b>three distinct challenges</b>,
					each corresponding to a specific control task arising in
					traditional solvers. Participants can compete in any subset
					of those challenges, and one winner will be declared for
					each.
				</p>
				<ul class="features">
					<li>
						<h3><a href="#primal-task" class="button">Primal task</a></h3>
						<p>Produce feasible solutions, in order to minimize the <em>primal integral</em> over time.</p>
					</li>
					<li>
						<h3><a href="#dual-task" class="button">Dual task</a></h3>
						<p>Select branching variables, in order to minimize dual the <em>dual integral</em> over time.</p>
					</li>
					<li>
						<h3><a href="#config-task" class="button">Configuration task</a></h3>
						<p>Choose the best solver parameters, in order to minimize the <em>primal-dual integral</em> over time.</p>
					</li>
				</ul>
				<p style="text-align: center;">
					<img style="border: 0; border-radius: 0; width: 50%;" src="images/primal-dual.png" alt="Primal-dual bound solving curves"/>
					<br/>
					Primal and dual bounds evolution vs solving time
					(for a minimization MILP instance).
					Note that this figure
					shows the primal and dual integrals minus
					\(T\mathbf{c}^\top \mathbf{x}^\star\), which takes a
					constant value for a particular instance.
				</p>
			</div>
		</div>
		<div id="primal-task" class="content" style="padding-top: 4em; border-top: solid 1px #dddddd;">

			<h2>Primal task - Finding feasible solutions</h2>

			<p>
				The primal task deals with finding good <b>primal solutions</b>
				at the root node of the branch-and-bound tree. To that end,
				the environment (SCIP solver) will not perform any branching
				but will enter an infinite loop at the root node, which will
				collect the agent's solutions, evaluate their
				feasibility, and update the overall best solution reached so
				far, thus lowering the current <b>primal bound</b> (upper bound).
				The metric of interest for this task is the primal integral,
				which takes into account the speed at which the primal bound
				decreases over time. To model a realistic scenario, each problem
				instance will have been preprocessed by SCIP (problem
				reduction, cutting
				planes etc.), and the root linear program (LP) relaxation will have
				been solved before the participants are asked to produce
				feasible solutions.
				To prevent SCIP from searching for primal solutions by itself,
				all primal heuristics will be deactivated.
 				In order to compute this metric unambiguously, even when no solution has been found yet,
				we provide an initial primal bound (trivial solution value) for each instance, which is to be
				given to SCIP at the beginning of the solving
				process in the form of a user objective limit.
			</p>
			<dl class="description">
				<dt>
					Environment	
				</dt>
				<dd>
					The solver is stopped at the root node after the root
					LP has been solved and enters an infinite loop. At each
					transition, the environment evaluates the given solution
					candidate and updates the primal bound. Nothing else
					happens. The solver remains in the <a href="https://www.scipopt.org/doc/html/type__set_8h.php#ac8ea6cabb843c57e1232f3132959e197">SOLVING</a>
					stage until the episode terminates (time
					limit reached, or when the problem is solved).
				</dd>
				<dt>
					Action
				</dt>
				<dd>
					A solution candidate for the current problem (variable assignment values, <b>x</b>).
				</dd>
				<dt>
					Metric
				</dt>
				<dd>
					Primal integral.
				</dd>
				<dt>
					Time limit
				</dt>
				<dd>
					\(T=5\) minutes.
				</dd>
				<dt>
					Relevant literature:
				</dt>
				<dd>
					<ul class="papers">
					<li>
						<a href="https://papers.nips.cc/paper/2017/hash/d9896106ca98d3d05b8cbdf4fd8b13a1-Abstract.html">
						<i>Learning Combinatorial Optimization Algorithms over Graphs</i>
						</a>, Dai et al., NeurIPS'17
					</li>
					<li>
						<a href="https://proceedings.neurips.cc/paper/2018/hash/9fb4651c05b2ed70fba5afe0b039a550-Abstract.html">
						<i>Reinforcement Learning for Solving the Vehicle Routing Problem</i>
						</a>, Nazari et al., NeurIPS'18
					</li>
					<li>
						<a href="https://proceedings.neurips.cc/paper/2018/hash/8d3bba7425e7c98c50f52ca1b52d3735-Abstract.html">
						<i>Combinatorial Optimization with Graph Convolutional Networks and Guided Tree Search</i>
						</a>, Li et al., NeurIPS'18
					</li>
					<li>
						<a href="https://deepmind.com/research/publications/Solving-Mixed-Integer-Programs-Using-Neural-Networks">
						<i>Solving Mixed Integer Programs Using Neural Networks</i>
						</a>, Nair et al., 2020 
					</li>
					</ul>
				</dd>
			</dl>
		</div>

		<div id="dual-task" class="content" style="padding-top: 4em; border-top: solid 1px #dddddd;">

			<h2>Dual task - Branching</h2>

			<p>
				The dual task deals with obtaining tight optimality guarantees
				(dual bounds) via branching. Making good <b>branching decisions</b>
				is regarded as a critical component of modern branch-and-bound
				solvers, yet has received little theoretical understanding to
				this day (see <a href="https://link.springer.com/article/10.1007%2Fs11750-017-0451-6">Lodi et al., 2017</a>).
				In this task, the environment will run a full-fledged
				branch-and-cut algorithm with SCIP, and the participants
				will only control the solver's branching decisions. The metric
				of interest is the dual integral,
				which considers the speed at which the
				<b>dual bound</b> increases over
				time. Also, all primal heuristics will be
				deactivated, so that the focus is only on proving
				optimality via branching.
			</p>
			<dl class="description">
				<dt>
					Environment	
				</dt>
				<dd>
					Traditional branch-and-bound algorithm. The solver stops
					after each node is processed (LP solved), receives a
					branching decision, performs branching, and selects the
					next open node to process.
					The solver remains in the <a href="https://www.scipopt.org/doc/html/type__set_8h.php#ac8ea6cabb843c57e1232f3132959e197">SOLVING</a>
					stage until the episode terminates (time
					limit reached, or when the problem is solved).
				</dd>
				<dt>
					Action
				</dt>
				<dd>
					One of the current node's branching
					candidates (non-fixed integer variables). Only single-variable
					branching is allowed.
				</dd>
				<dt>
					Metric
				</dt>
				<dd>
					Dual integral.
				</dd>
				<dt>
					Time limit
				</dt>
				<dd>
					\(T=15\) minutes.
				</dd>
				<dt>
					Relevant literature:
				</dt>
				<dd>
					<ul class="papers">
					<li>
						<a href="https://dl.acm.org/doi/10.5555/3015812.3015920">
						<i>Learning to Branch in Mixed Integer Programming</i>
						</a>, Khalil et al., AAAI'16
					</li>
					<li>
						<a href="https://link.springer.com/article/10.1007/s11750-017-0451-6">
						<i>On Learning and Branching: a Survey</i>
						</a>, Lodi et al., TOP, 2017
					</li>
					<li>
						<a href="http://proceedings.mlr.press/v80/balcan18a.html">
						<i>Learning to Branch</i>
						</a>, Balcan et al., ICML'18
					</li>
					<li>
						<a href="https://papers.nips.cc/paper/2019/hash/d14c2267d848abeb81fd590f371d39bd-Abstract.html">
						<i>Exact Combinatorial Optimization with Graph Convolutional Neural Networks</i>
						</a>, Gasse et al., NeurIPS'19
					</li>
					<li>
						<a href="https://papers.nips.cc/paper/2020/hash/d1e946f4e67db4b362ad23818a6fb78a-Abstract.html">
						<i>Hybrid Models for Learning to Branch</i>
						</a>, Gupta et al., NeurIPS'20
					</li>
					<li>
						<a href="https://deepmind.com/research/publications/Solving-Mixed-Integer-Programs-Using-Neural-Networks">
						<i>Solving Mixed Integer Programs Using Neural Networks</i>
						</a>, Nair et al., 2020 
					</li>
					</ul>
				</dd>
			</dl>

		</div>
		<div id="config-task" class="content" style="padding-top: 4em; border-top: solid 1px #dddddd;">

			<h2>Configuration task - Choosing solver parameters</h2>

			<p>
				The configuration task deals with deciding on a good
				<b>parameterization</b> of the solver for a given problem instance.
				The environment required for this task is more straightforward
				than for the two previous ones since it involves only a single
				decision for the agents (i.e., contextual bandit problem).
				Participants are allowed to tune any of the existing parameters
				of SCIP (except parameters regarding the computation of time).
				They can choose between providing a fixed set of
				parameters that work well on average for each problem
				benchmark or producing instance-specific parameterizations
				based on each instance's characteristics. The metric of
				interest for this task is the <b>primal-dual gap</b> integral,
				which combines both improvements from the dual and from the
				primal side over time. In order to compute this metric unambiguously,
				even when no primal or dual bound exists,
				we provide both an initial primal bound (trivial solution value) and
				an initial dual bound (pre-computed root LP solution value) for each instance.
			</p>
			<dl class="description">
				<dt>
					Environment	
				</dt>
				<dd>
					The solver loads a problem instance and immediately
					stops. It then receives a parameterization, applies it,
					and pursues with the solving process until it terminates
					(time limit reached, or when the problem is solved).
					During the first and only transition, the solver is in the
					<a href="https://www.scipopt.org/doc/html/type__set_8h.php#ac8ea6cabb843c57e1232f3132959e197">PROBLEM</a>
					stage. As such, participants will not be able to extract
					advanced features from the solver, such as those
					relying on the LP being solved.
				</dd>
				<dt>
					Action
				</dt>
				<dd>
					A set of <a href="https://www.scipopt.org/doc/html/PARAMETERS.php">SCIP parameters</a>,
					in the form of a key/value dictionary.
				</dd>
				<dt>
					Metric
				</dt>
				<dd>
					Primal-dual gap integral.
				</dd>
				<dt>
					Time limit
				</dt>
				<dd>
					\(T=15\) minutes.
				</dd>
				<dt>
					Relevant literature
				</dt>
				<dd>
					<ul class="papers">
						<li>
							<a href="https://dl.acm.org/doi/10.1007/978-3-642-25566-3_40">
							<i>Sequential model-based optimization for general algorithm configuration</i>
							</a>, Hutter et al., LION'11
						</li>
					</ul>
				</dd>
			</dl>

		</div>
	</section>

	<!-- Metrics-->
	<section id="metrics" class="main">
		<div class="content">
			<header class="major">
				<h2>Metrics</h2>
			</header>
			<p>
				Each of the three challenges, the primal task, the
				dual task and the configuration task,
				is associated with a specific <b>evaluation metric</b>
				that reflects a different objective. Here we describe how each
				metric is computed over a single problem instance, while the final
				goal of the participants is to optimize this metric in
				expectation over a <b>hidden collection of test instances</b>.
			</p>
			<p>
				Because our evaluation metrics are
				time-dependent, all evaluations will be run on the same
				hardware setup, including one CPU core and one GPU card,
				which will be communicated at the start of the competition.
				For practical reasons, for each task, a maximum <b>time
				budget</b> \(T\) is given to process each test instance (5,
				15 and 15 minutes respectively for the primal,
				dual and configuration tasks),
				after which the environment necessarily terminates.
				Participants should therefore focus on taking both
				<b>good</b> and <b>fast</b> decisions.
			</p>
			<p>
				In the following we consider instances of mixed-integer linear programs (MILPs)
				expressed as follows:
				\[
				\begin{eqnarray}
					\underset{\mathbf{x}}{\operatorname{arg\,min}} \quad \mathbf{c}^\top\mathbf{x} && \\
					\text{subject to} \quad \mathbf{A}^\top\mathbf{x} & \leq & \mathbf{b} \text{,} \\
					\mathbf{x} & \in & \mathbb{Z}^p \times \mathbb{R}^{n-p}
					\text{,}
				\end{eqnarray}
				\]
				where \(\mathbf{c} \in \mathbb{R}^n\)
				denotes the coefficients of the linear objective,
				\(\mathbf{A} \in \mathbb{R}^{m \times n}\) and \(\mathbf{b} \in \mathbb{R}^m\)
				respectively denote the coefficients and upper bounds of the
				linear constraints, while \(n\) is the total number of variables,
				\(p \leq n\) is the number of integer-constrained variables, and
				\(m\) the number of linear constraints.
			</p>
		</div>
		<div class="spotlight">
			<div class="content">
				<dl class="description">
					<dt>
						Primal integral
					</dt>
					<dd>
						<p>
							This objective measures the area under the curve of
							the solver's <b>primal bound</b> (a.k.a.
							global upper bound), which corresponds to the value of
							the best feasible solution found so far. By providing
							better feasible solutions over time, the value of the primal bound
							decreases.
							With a time limit \(T\), the primal integral expresses as:
							\[
								\int_{t=0}^{T} \mathbf{c}^\top \mathbf{x}^\star_t\;\mathrm{d}t - T\mathbf{c}^\top\mathbf{x}^\star
								\text{,}
							\]
							where \(\mathbf{x}^\star_t\) is the best feasible
							solution found at time \(t\) (so that
							\(\mathbf{c}^\top \mathbf{x}^\star_t\) is the primal
							bound at time \(t\)), and \(T\mathbf{c}^\top\mathbf{x}^\star\)
							is an instance-specific constant that depends on the
							optimal solution \(\mathbf{x}^\star\).
							The primal integral is to be <b>minimized</b>, and takes
							an optimal value of 0.
						</p>
						<p>
							<em>
								Note: to compute this metric unambiguously, a trivial
								initial solution \(x^\star_0\) is always provided to SCIP
								at the beginning of the solving process. Also,
								the constant term \(\mathbf{c}^\top\mathbf{x}^\star\)
								can be safely ignored at training time when
								participants train their control policy, as the
								learning problem is equivalent.
								At test time however, when we will evaluate the
								participant submissions, this constant
								term (or a proper substitute) will be incorporated
								in the reported metric.
							</em>
						</p>
					</dd>
				</dl>
			</div>
			<span class="image" style="border: 0; border-radius: 0;">
				<img style="border: 0; border-radius: 0; width: 20em; margin: auto;" src="images/primal-integral.png" alt="Primal integral illustration"/>
			</span>
		</div>
		<div class="spotlight">
			<div class="content">
				<dl class="description">
					<dt>
						Dual integral
					</dt>
					<dd>
						<p>
							This objective measures the area over the curve of the
							solver's <b>dual bound</b> (a.k.a. global lower bound),
							which usually corresponds to a solution of a valid
							relaxation of the MILP. By branching, the LP relaxations
							corresponding to the branch-and-bound tree leaves get
							tightened, and the dual bound increases over time.
							With a time limit \(T\), the dual
							integral expresses as:
							\[
								T\mathbf{c}^\top\mathbf{x}^\star - \int_{t=0}^{T} \mathbf{z}^\star_t\;\mathrm{d}t
								\text{,}
							\]
							where \(\mathbf{z}^\star_t\) is the best dual bound at
							time \(t\), and \(T\mathbf{c}^\top\mathbf{x}^\star\) is
							an instance-specific constant that depends on the
							optimal solution value \(\mathbf{c}^\top\mathbf{x}^\star\).
							The dual integral is to be <b>minimized</b>, and takes
							an optimal value of 0.
						</p>
						<p>
							<em>
								Note: in the context of branching, this metric is unambiguous to
								compute, as the root node of the tree always provides an
								initial dual bound \(\mathbf{z}^*_0\)
								at the beginning of branching. Here again,
								the constant term \(\mathbf{c}^\top\mathbf{x}^\star\)
								can be safely ignored for training,
								but it will be incorporated (or a proper substitute)
								in the metrics that we will report when evaluating
								the participants submissions.
							</em>
						</p>
					</dd>
				</dl>
			</div>
			<span class="image" style="border: 0; border-radius: 0;">
				<img style="border: 0; border-radius: 0; width: 20em; margin: auto;" src="images/dual-integral.png" alt="Dual integral illustration"/>
			</span>
		</div>
		<div class="spotlight">
			<div class="content">
				<dl class="description">
					<dt>
						Primal-dual gap integral
					</dt>
					<dd>
						<p>
							This objective measures the area between two curves, the
							solver's <b>primal bound</b> and the solver's
							<b>dual bound</b>. As such, this metric benefits
							both from improvements obtained from the primal side
							(finding good feasible solutions), and on the dual
							side (producing a tight optimality certificate).
							With a time limit \(T\), the
							primal-dual gap integral expresses as:
							\[
								\int_{t=0}^{T} \mathbf{c}^\top \mathbf{x}^\star_t - \mathbf{z}^\star_t\;\mathrm{d}t
								\text{.}
							\]
							The primal-dual gap integral is to be <b>minimized</b>,
							and take an optimal value of 0.
						</p>
						<p>
							<em>
								Note: in the context of algorithm
								configuration, an initial value is required for
								the two curves at time \(t=0\). Therefore we
								always provide both an initial trivial
								solution \(x^\star_0\) and a valid initial
								dual bound \(z^\star_0\) to SCIP for this task.
							</em>
						</p>
					</dd>
				</dl>
			</div>
			<span class="image" style="border: 0; border-radius: 0;">
				<img style="border: 0; border-radius: 0; width: 20em; margin: auto;" src="images/primal-dual-gap-integral.png" alt="Primal-dual gap integral illustration"/>
			</span>
		</div>
	</section>

	<!-- Datasets -->
	<section id="datasets" class="main">
		<div class="content">
			<header class="major">
				<h2>Datasets</h2>
			</header>
			<p>
				For each individual challenge, participants will be
				evaluated on <b>three problem benchmarks</b> from diverse application
				areas. Participants can provide a different
				decision-making code (algorithmic solution or trained
				ML model) for each of the benchmarks, or a single code that
				works for all benchmarks.
			</p>
			<p>
				A problem benchmark consists in a collection of
				<b>mixed-integer linear program</b>
				(MILP) instances in the standard
				<a href="https://en.wikipedia.org/wiki/MPS_(format)">MPS file format</a>.
				Each benchmark is
				split into a <b>training</b> and a <b>test</b> set, originating from
				the same problem distribution. While the training instances
				are made public at the beginning of the competition for
				participants to train their models, the test instances will
				be kept hidden for evaluation purposes and will
				only be revealed at the end of the competition.
			</p>
			<p>
				<em>
					Note: for each problem benchmark we suggest a pre-established split
					of the training instances into two distinct collections: <b>train</b> and
					<b>valid</b>. This is only a suggestion, and all instance files in both
					those collections can be likely considered as training instances. There
					is no restriction regarding how participants should use the provided
					instances during training.
				</em>
			</p>
			<p>
			The first two problem benchmarks are inspired by real-life
			applications of large-scale systems at Google, while the third
			benchmark is an anonymous problem inspired by a real-world,
			large-scale industrial application.
			</p>
			<dl class="description">
				<dt>
					Problem benchmark 1: Balanced Item Placement
				</dt>
				<dd>
					This problem deals with spreading items (e.g., files or
					processes) across containers (e.g., disks or machines)
					utilizing them <em>evenly</em>. Items can have multiple
					copies, but at most, one copy can be placed in a single
					bin. The number of items that can be moved is
					constrained, modeling the real-life situation of a
					live system for which some placement already exists. Each
					problem instance is modeled as a MILP, using a
					multi-dimensional multi-knapsack formulation. This
					dataset contains 10000 training instances
					(pre-split into 9900 train and 100 valid instances).
				</dd>
				<dt>
					Problem benchmark 2: Workload Apportionment
				</dt>
				<dd>
					This problem deals with apportioning workloads (e.g.,
					data streams) across as few workers (e.g., servers) as
					possible. The apportionment is required to be robust to
					any one worker's failure. Each instance problem is modeled
					as a MILP, using a bin-packing with apportionment
					formulation. This dataset contains 10000 training
					instances (pre-split into 9900 train and 100 valid instances).
				</dd>
				<dt>
					Problem benchmark 3: Anonymous Problem
				</dt>
				<dd>
					The MILP instances corresponding to this benchmark are
					assembled from a public dataset, whose origin is kept
					secret to prevent cheating.
					Reverse-engineering for the purpose of recovering the
					test set is explicitly forbidden
					(see <a href="#rules">rules</a>). This dataset contains
					118 training instances (pre-split into 98 train and 20 valid instances).
				</dd>
			</dl>
		</div>
	</section>

	<!-- Rules -->
	<section id="rules" class="main">
		<div class="content">
			<header class="major">
				<h2>Rules</h2>
			</header>
			<p>
				The spirit of the competition is as follows:
			</p>
			<ul>
				<li>
					we encourage contributions from both the
					<b>OR and ML communities</b> by explicitly allowing non-ML
					submissions;
				</li>
				<li>
					we encourage student participation with a
					<b>dedicated student leaderboard</b>;
				</li>
				<li> we encourage
					original contributions
					by specifically making the use of <b>highly-engineered
					commercial solvers prohibited</b>.
				</li>
			</ul>
			<p>
				Participants must adhere to the following rules:
			</p>
			<dl class="description">
				<dt>
					Eligibility
				</dt>
				<dd>
				<ol>
					<li>
						Participants can work in teams.
					</li>
					<li>
						Participants can submit codes based on a machine
						learning model, a human-designed algorithm, or any
						combination of the two.
					</li>
					<li>
						Participants are not allowed to use commercial
						software in their code. The use of solvers such as
						CPLEX, Gurobi, or FICO XPress is explicitly forbidden.
					</li>
					<li>
						Student-only teams are eligible to a separate student
						leaderboard, in addition to the main leaderboard of
						the competition. A graduated PhD is not considered a
						student.
					</li>
				</ol>
				</dd>
				<dt>
					Data
				</dt>
				<dd>
				<ol>
					<li>
    					The use of supplementary existing open-source
						datasets, e.g., for pre-training, is permitted
						provided they are credited.
					</li>
					<li>
						The use of private, proprietary datasets is not
						permitted.
					</li>
					<li>
						In order to prevent cheating, the evaluation data
						sets will be kept hidden to the participants during
						the competition.
					</li>
					<li>
						Participants are free and encouraged to extract
						original features from the solver for training and
						evaluation, though the Python interface of SCIP,
						PySCIPOpt.
					</li>
				</ol>
				</dd>
				<dt>
					Submission
				</dt>
				<dd>
				<ol>
					<li>
    					The submitted codes must be written in Python, and
						must run in the evaluation environment which we
						provide.
					</li>
					<li>
    					Parallel implementations using multiple processes
						or multiple threads are allowed, although the hardware
						on which the codes will be evaluated is single-core.
					</li>
					<li>
    					The evaluation environment does not have access to
						any external network, to prevent any information leak.
					</li>
					<li>
    					Users may make use of open source libraries given
						proper attribution. At the end of the competition,
						we encourage all code to be open-sourced so the
						results can be reproduced.
					</li>
					<li>
    					The evaluation environment will provide a basic
						ML ecosystem (Tensorflow, Pytorch, Scikit-learn).
						Additional libraries will be added to the evaluation
						environment upon reasonable requests.
					</li>
					<li>
						At the end of the competition, the winners are
						expected to provide a description of the method
						they used.
					</li>
				</ol>
				</dd>
				<dt>
					Cheating prevention
				</dt>
				<dd>
				<ol>
					<li>
						Participants are forbidden to interact with the SCIP
						solver in any other way than the one intended, that
						is, extracting information or providing a control
						decision related to the task at hand. Any interaction
						with SCIP that results in changes of the solver's
						internal state will be considered cheating.
					</li>
					<li>
						Some datasets have been anonymized, as they
						rely on publicly accessible data. Any attempt at
						reverse-engineering for the purpose of recovering
						information about the test set is forbidden.
					</li>
					<li>
						Any instance of cheating, defined as violation of the
						rules above or any other attempt to circumvent the
						spirit and intent of the competition, as determined
						by the organizers, will result in the invalidation of
						all of the offending team’s submissions and a
						disqualification from the competition.
					</li>
				</ol>
				</dd>
			</dl>
			<p>
				For each task, the winners will be declared as follows:
			</p>
			<dl class="description">
				<dt>
					Ranking rules
				</dt>
				<dd>
				<ul>
					<li>
						Each team will be evaluated separately
						on each of the three benchmark datasets according the
						task's metric, i.e., primal integral, dual integral,
						or primal-dual integral. This metric will be averaged
						across all instances in the test dataset, resulting in
						an individual ranking for each dataset. For example, for the primal task,
						team A might obtain ranks 3, 8, 1 respectively in the
						three problem benchmark, while team B obtains ranks 2, 2, 15.
					</li>
					<li>Then, for each team those three ranks will be multiplied
						together to obtain the overall score of the team. For
						example, team A will obtain a score of 3x8x1=24 while
						team B obtains 2x2x15=60.
					</li>
					<li>
						The team with the lowest overall score wins.
					</li>
				</ul>
				</dd>
			</dl>
		</div>
	</section>

	<!-- Getting started -->
	<section id="getting-started" class="main">
		<div class="content">
			<header class="major">
				<h2>Getting started</h2>
			</header>
			<p>
				<a href="https://forms.gle/pv6aaXxZ9iGYVCtj9">Registration form</a>:
				register your team and subscribe to the competition's
				mailing list.
			</p>
			<p>
				<a href="https://github.com/ds4dm/ml4co-competition">GitHub repository</a>:
				get started and access the datasets, started packages, and
				technical documentation.
			</p>
		</div>
	</section>

	<!-- Leaderboard -->
	<section id="leaderboard" class="main">
		<div class="content">
			<header class="major">
				<h2>Leaderboard</h2>
				Last update: August 10th.
			</header>
			<dl class="description">
				<dt>
					Global leaderboard
				</dt>
				<dd>
				Primal task
				<table>
				<tr>
					<th rowspan="2">team</th>
					<th colspan="3">item_placement</th>
					<th colspan="3">load_balancing</th>
					<th colspan="3">anonymous</th>
					<th rowspan="2">final rank</th>
				</tr>
				<tr>
					<th>metric</th>
					<th>(unshifted)</th>
					<th>rank</th>
					<th>metric</th>
					<th>(unshifted)</th>
					<th>rank</th>
					<th>metric</th>
					<th>(unshifted)</th>
					<th>rank</th>
				</tr>
				</table>
				Dual task
				<table>
				<tr>
					<th rowspan="2">team</th>
					<th colspan="3">item_placement</th>
					<th colspan="3">load_balancing</th>
					<th colspan="3">anonymous</th>
					<th rowspan="2">final rank</th>
				</tr>
				<tr>
					<th>metric</th>
					<th>(unshifted)</th>
					<th>rank</th>
					<th>metric</th>
					<th>(unshifted)</th>
					<th>rank</th>
					<th>metric</th>
					<th>(unshifted)</th>
					<th>rank</th>
				</tr>
				<tr>
					<th>Nuri</th>
					<td>5262.38</td>
					<td>(-3995.58)</td>
					<td>1</td>
					<td>7158.41</td>
					<td>(-634069.09)</td>
					<td>1</td>
					<td>7186197.02</td>
					<td>(-59777670.04)</td>
					<td>1</td>
					<td>1</td>
				</tr>
				<tr>
					<th>uofx</th>
					<td>6168.15</td>
					<td>(-3089.82)</td>
					<td>2</td>
					<td>nan</td>
					<td>(nan)</td>
					<td>2</td>
					<td>nan</td>
					<td>(nan)</td>
					<td>2</td>
					<td>8</td>
				</tr>
				</table>
				Config task
				<table>
				<tr>
					<th rowspan="2">team</th>
					<th colspan="3">item_placement</th>
					<th colspan="3">load_balancing</th>
					<th colspan="3">anonymous</th>
					<th rowspan="2">final rank</th>
				</tr>
				<tr>
					<th>metric</th>
					<th>(unshifted)</th>
					<th>rank</th>
					<th>metric</th>
					<th>(unshifted)</th>
					<th>rank</th>
					<th>metric</th>
					<th>(unshifted)</th>
					<th>rank</th>
				</tr>
				<tr>
					<th>EI-OROAS</th>
					<td>11834.33</td>
					<td>(11834.33)</td>
					<td>1</td>
					<td>24930.26</td>
					<td>(24930.26)</td>
					<td>1</td>
					<td>843057679.73</td>
					<td>(843057679.73)</td>
					<td>1</td>
					<td>1</td>
				</tr>
				</table>
				</dd>
			</dl>
			<dl class="description">
				<dt>
					Student leaderboard
				</dt>
				<dd>
				Primal task
				<table>
				<tr>
					<th rowspan="2">team</th>
					<th colspan="3">item_placement</th>
					<th colspan="3">load_balancing</th>
					<th colspan="3">anonymous</th>
					<th rowspan="2">final rank</th>
				</tr>
				<tr>
					<th>metric</th>
					<th>(unshifted)</th>
					<th>rank</th>
					<th>metric</th>
					<th>(unshifted)</th>
					<th>rank</th>
					<th>metric</th>
					<th>(unshifted)</th>
					<th>rank</th>
				</tr>
				</table>
				Dual task
				<table>
				<tr>
					<th rowspan="2">team</th>
					<th colspan="3">item_placement</th>
					<th colspan="3">load_balancing</th>
					<th colspan="3">anonymous</th>
					<th rowspan="2">final rank</th>
				</tr>
				<tr>
					<th>metric</th>
					<th>(unshifted)</th>
					<th>rank</th>
					<th>metric</th>
					<th>(unshifted)</th>
					<th>rank</th>
					<th>metric</th>
					<th>(unshifted)</th>
					<th>rank</th>
				</tr>
				</table>
				Config task
				<table>
				<tr>
					<th rowspan="2">team</th>
					<th colspan="3">item_placement</th>
					<th colspan="3">load_balancing</th>
					<th colspan="3">anonymous</th>
					<th rowspan="2">final rank</th>
				</tr>
				<tr>
					<th>metric</th>
					<th>(unshifted)</th>
					<th>rank</th>
					<th>metric</th>
					<th>(unshifted)</th>
					<th>rank</th>
					<th>metric</th>
					<th>(unshifted)</th>
					<th>rank</th>
				</tr>
				</table>
				</dd>
			</dl>
		</div>
	</section>

</div>

<!-- Footer -->
<footer id="footer">
	<section>
		<h2>Organizers</h2>
		<p>
			<a href="https://research.monash.edu/en/persons/simon-bowly">Simon Bowly</a>,
			<a href="https://www.cs.ubc.ca/~cchris13/">Chris Cameron</a>,
			<a href="https://www.polymtl.ca/expertises/cappart-quentin-0">Quentin Cappart</a>,
			<a href="https://ca.cs.uni-bonn.de/doku.php?id=people:charfreitag">Jonas Charfreitag</a>,
			<a href="http://www.cs.toronto.edu/~lcharlin/">Laurent Charlin</a>,
			<a href="https://www.didierchetelat.com/">Didier Chételat</a>,
			<a href="https://cerc-datascience.polymtl.ca/person/justin-dumouchelle/">Justin Dumouchelle</a>,
			<a href="http://www.maximegasse.com/">Maxime Gasse</a>,
			<a href="https://www.zib.de/gleixner">Ambros Gleixner</a>,
			<a href="https://akazachk.github.io">Aleksandr M. Kazachkov</a>,
			<a href="https://ekhalil.com">Elias B. Khalil</a>,
			<a href="https://research.google/people/PawelLichocki/">Pawel Lichocki</a>,
			<a href="https://cerc-datascience.polymtl.ca/person/dr-andrea-lodi/">Andrea Lodi</a>,
			<a href="https://mlubin.github.io/">Miles Lubin</a>,
			<a href="https://www.cs.toronto.edu/~cmaddis/">Chris J. Maddison</a>,
			<a href="http://www.christophermorris.info">Christopher Morris</a>,
			<a href="https://scholar.google.com/citations?user=_KQQtY8AAAAJ">Dimitri J. Papageorgiou</a>,
			<a href="https://hanalog.polymtl.ca/en/person/augustin-parjadis-de-la-riviere/">Augustin Parjadis</a>,
			<a href="http://www.pokutta.com">Sebastian Pokutta</a>,
			<a href="https://www.prouvost.dev">Antoine Prouvost</a>,
			<a href="https://github.com/lascavana">Lara Scavuzzo</a>,
			<a href="https://cerc-datascience.polymtl.ca/person/giulia-zarpellon/">Giulia Zarpellon</a>.
		</p>
		<dl class="alt">
			<dt>Contact</dt>
			<dd><a href="#">maxime.gasse@polymtl.ca</a></dd>
		</dl>
	</section>
	<section>
		<h2>Supporting organizations</h2>
		<dl class="alt">
			<dt><a href="https://cerc-datascience.polymtl.ca/">DS4DM</a></dt>
			<dd>Data Science for Real-Time Decision-Making</dd>
			<dt><a href="https://www.zib.de/">ZIB</a></dt>
			<dd>Zuse Institute Berlin</dd>
			<dt><a href="https://research.google/">Google</a></dt>
			<dd>Google Research</dd>
			<dt>CC</dt>
			<dd><a href="https://www.computecanada.ca/">Compute Canada</a> and regional organizations <a href="https://www.calculquebec.ca/en/">Calcul Québec</a> and <a href="https://www.westgrid.ca/">Westgrid</a></dd>
		</dl>
	</section>
	<p class="copyright">
		&copy; CERC DS4DM. Design by <a href="https://html5up.net">HTML5 UP</a>.
	</p>
</footer>

</div>

<!-- Scripts -->
<script src="/assets/js/jquery.min.js"></script>
<script src="/assets/js/jquery.scrollex.min.js"></script>
<script src="/assets/js/jquery.scrolly.min.js"></script>
<script src="/assets/js/skel.min.js"></script>
<script src="/assets/js/util.js"></script>
<!--[if lte IE 8]><script src="/assets/js/ie/respond.min.js"></script><![endif]-->
<script src="/assets/js/main.js"></script>
<!-- Goatcounter analytics -->
<script>
	window.goatcounter = { path: function(p) { return location.host + p } }
</script>
<script data-goatcounter="https://ecoleai.goatcounter.com/count" async src="//gc.zgo.at/count.js"></script>

<!-- MathJax -->
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


</body>
</html>
